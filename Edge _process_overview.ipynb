{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Edge Detection on Plant Imagery for North Alaskan Coast\nThis project is designed to create a method of detecting coastline\nin a set of given satellite imagery from planet labs. Specifically\nfor the following code the coastlines that are being detected are \nlocated in northern Alaska. With the goal for this project being\nthe accurate coastline detection of over 1000 km of northern Alaskan\ncoastline to measure coastal erosion.\n\nTo do this the following edge detection and threshold methods have\nbeen used: Canny edge detection, Sobel Edge Detection, \nNormalized Difference Water Index (NDWI), Holistically-Nested\nEdge Detection, and ISODATA clustering. Each of these methods have\ntheir strong and weak points when it comes to clustering. I will go\nover a outline of how each method work, show the method results on \ntwo sample images from the north Alaskan coast, and describe why\nthe method was either chosen for further use in the project or \ndropped.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Canny Edge Detection\nCanny edge detection is a multi-stage process used to detect edge on\na wide array of images.\n\nStep 1:\nWe first have to import opencv and numpy in addition to handle the images\nthen load in the image as grayscale ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import cv2\nimport numpy as np\nimage \u003d \"/home/nelson/PycharmProjects/coastline_detection_with_LANDSAT/good_images/output2.jpg\"\nimage \u003d cv2.imread(image)\nimage \u003d cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # cv2.COLOR_BGR2GRAY one of opencv many color change options",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/Original Grayscale.png \"Original Grayscale\")\nNow we need to apply a blur to the image. I know that applying a blur\nseems counter intuitive but it is useful for removing noise at the \nedge locations of the image. For this example we will be using a \ngaussian blur of size 5x5. This should remove most of the noise in\nour image.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "blur \u003d cv2.GaussianBlur(image, (5, 5), 0)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/Blurred.png \"Blurred\")\nNow we can apply canny edge detection on the blurred image. Part of \ncanny edge detection is entering in the upper and lower bounds of \nthe pixels in the image. Any pixels with a value higher than the upper\nbound is automatically considered an edge. While any pixels below the\nlower bound threshold are considered to be non-edges and are to be \ndiscarded. Values between the two thresholds are considered to be either\nedges or none edges based on their connectivity to other pixels. \nOne method about thinking of this process is that edges are the \npoints where two gaussian/bell curves meet.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "canny \u003d cv2.Canny(blur, 30, 150)  # these values are just random",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/Canny.png \"Canny\")\nAs you can see in this image canny edge detection works pretty well.\nYou can see continuous edges from the coastline. It also picks up \nthe ponds and lakes that are also in the image. The main problem with\nCanny Edge detection though is that it relies way to heavily on human\ninputted values for determining edges. This makes trying to use this process\na poor choice for large amounts of images when a large variety of \ndifferent conditions exist for those images. Exactly the situation for\nthis project. An example of this is the following image with Canny Edge\ndetection applied. \n![](Edge_process_overview images/Original2 Grayscale.png \"image 2\")\nCanny edge applied with the same values\n![](Edge_process_overview images/canny2.png \"Canny on image 2\")\nYou\u0027ll see in this image that in the upper left corner parts of the \nisland end up getting cut off. \n\nIn the end though Canny edge is still a really good edge detection choice\nin most cases",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Sobel Edge Detection\nSobel Edge Detection is an approximation of the derivative of the image separated in\nthe x and y directions.  These gradients are then added together. \n\nStep 1:\nThis is also an opencv function. Lucky we already have opencv imported.\nWe are also going to be using a grayscale image again. Which is still imported\nas the image object. We then apply the opencv sobel function to get the x and y\ngradient. To perform this operation we also need to convert the int8 pixels into 64 bit floats.\nOtherwise information will be lost since we are calculating gradients.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "sobelX \u003d cv2.Sobel(image, cv2.CV_64F, 1, 0)\nsobelY \u003d cv2.Sobel(image, cv2.CV_64F, 0, 1)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/sobelx.png \"Sobel X gradient\")\n![](Edge_process_overview images/sobely.png \"Sobel Y gradient\")\nStep 2:\nwe then have to convert the 64 float values back into int8. So that we have pixel\nvalues that are readable for image displaying. Followed by adding the x and y gradients together.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "sobelX \u003d np.uint8(np.absolute(sobelX))\nsobelY \u003d np.uint8(np.absolute(sobelY))\nsobelCombined \u003d cv2.bitwise_or(sobelX, sobelY)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/sobelCombined.png \"Sobel Combined gradient\")\nAS you can see this image shows the edges really well. The main problem though is that\nthere is a bunch of additional noise that is also in the image. This noise shows up in\nthe area of the image where ocean would normally be, Getting rid of these noisy pixels is\nnecessary when an edge detection process is required to to have a high level accuracy.\nThus sort of ruling it out for accurate coastline measurements. The reason that I say sort of is that\nSobel edge detection is part of Canny Edge detection. The part of Canny Edge that \noperates between the threshold parameters contains Sobel edge detection within it.\nWhich is why Sobel can be useful. It gives you the possibility to detect edges that\nyou otherwise might miss with Canny Edge.\n\n# ISODATA Thresholding\nISODATA thresholding is a clustering algorithm that takes the histogram of the entire image\nand divides them into two separate groups of data. In our case it separates the water from the land.\nIt matters in this case as to what band layer that this process is applied to. The near infrared \nis the layer that gets the best results due to the greatest difference between water and land.\n\nStep 1:\nFor this process we need to use the sckit-image package which contains the appropriate \nfunctions to read a tiff file and an implemented ISODATA function.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": "from skimage import io, img_as_uint\nfrom skimage.filters import threshold_isodata\ntiff_image \u003d \"/home/nelson/PycharmProjects/coastline_detection_with_LANDSAT/\" \\\n             \"Oliktok OVR Files/671610_2013-07-21_RE5_3A_Analytic_clip.tif\"\ntif \u003d io.imread(tiff_image)  # importing the tiff file\nir_layer \u003d tif[4]  # the NIR layer of the tiff layer",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Step 2:\nWe then need to get the ISODATA threshold value. Followed with applying it to the \noriginal image. The resulting image is then saved in a png file which requires the\nconversion of the int16 pixel values to the int8 pixel values",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "thres \u003d threshold_isodata(ir_layer)\nresult \u003d ir_layer \u003e thres\nio.imsave(\"isodata_thres.png\", img_as_uint(result))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/isodata_thres.png \"ISODATA result\")\nAs you can see in the resulting image ISODATA has one of the best performing\ncoastline detection methods. Pulling out a continuous contour of the \ncoastline. Which an edge can easily be extracted through the used of Canny Edge.\nThis is only the case when there are enough land pixels in an image\nthough. If there are not enough land pixels in an image you instead get a mess \nof static noise in the image. This is easily with a change in the image file.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "tiff_image_bad \u003d \"/home/nelson/PycharmProjects/coastline_detection_with_LANDSAT/\" \\\n                 \"Oliktok OVR Files/671710_2013-07-21_RE5_3A_Analytic_clip.tif\"\ntif \u003d io.imread(tiff_image_bad)  # importing the tiff file\nir_layer \u003d tif[4]  # the NIR layer of the tiff layer\nthres \u003d threshold_isodata(ir_layer)\nresult \u003d ir_layer \u003e thres\nio.imsave(\"isodata_thres_bad.png\", img_as_uint(result))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/isodata_thres_bad.png \"ISODATA result bad\")\nAs you can see this image does not really show the coastline in this image.\n\nIn the end though out of all the methods that have been applied in this process\nISODATA has the best performance. Provided that enough land pixels have been\nincluded in the original image. It just means that when applying ISODATA threshold\nto an image make sure to test the result with another process to make sure no\nmistakes were made.\n\n# Normalized Difference Water Index (NDWI)\nNDWI uses the properties of the different band layers in the tiff files to \ndetermine the difference between water and land. It does this by taking \nadvantage of simple matrix math. \n\nStep 1:\nUse the image that was previously imported for the ISODATA threholding and \nperform the following math.\nNDWI \u003d (green band - near infrared band) / (green band + near infrared band)",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "ndwi_im \u003d (tif[1] - tif[4]) / (tif[1] + tif[4])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/ndwi.png \"NDWI results\")\nAs you can see in the resulting image when it comes to coastline extraction \nNDWI does not really perform all that well. It really breaks down when \nviewing the shore between the water and the land. This is due to NDWI\u0027s strong\npoint not being accuracy in determining the boundaries between water and land but\ninstead determining if there is water in an image. Making it a \nprocess that is likely not to be used very often in this project.\n\n# Holistically-Nested Edge Detection\nHolistic Edge is the final edge detection process that was implemented for this\nproject. It is the only edge detection process that utilizes a pre-trained neural network.\nBy using that neural network Holistic Edge is able to learn the hierarchical representations\nthat represent the edges in the image. Allowing for higher accuracy in performance on \ngeneral edge detection problems than any other method of edge detection in this project.\n\nStep 1:\nWe first have to import in the pre-trained model that will be used.\nThis is done in this project by using caffe and opencv.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "image \u003d \"/home/nelson/PycharmProjects/coastline_detection_with_LANDSAT/good_images/output2.jpg\"\nimage \u003d cv2.imread(image)\nholistic_proto_path \u003d \"hed_model/deploy.prototxt\"\nholistic_model_path \u003d \"hed_model/hed_pretrained_bsds.caffemodel\"\nnet \u003d cv2.dnn.readNetFromCaffe(holistic_proto_path, holistic_model_path)  # read model in",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Step 2:\nWe now need to create a class that we can use to crop layers of the network.\nAllowing us to derive in input shape, batch size, input channels, height and target width.\nWhich are then passed to each layer in the neural network.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "class CropLayer(object):\n    def __init__(self, params, blobs):\n        # initialize our starting and ending (x, y)-coordinates of\n        # the crop\n        self.startX \u003d 0\n        self.startY \u003d 0\n        self.endX \u003d 0\n        self.endY \u003d 0\n\n    def getMemoryShapes(self, inputs):\n        # the crop layer will receive two inputs -- we need to crop\n        # the first input blob to match the shape of the second one,\n        # keeping the batch size and number of channels\n        (inputShape, targetShape) \u003d (inputs[0], inputs[1])\n        (batchSize, numChannels) \u003d (inputShape[0], inputShape[1])\n        (H, W) \u003d (targetShape[2], targetShape[3])\n\n        # compute the starting and ending crop coordinates\n        self.startX \u003d int((inputShape[3] - targetShape[3]) / 2)\n        self.startY \u003d int((inputShape[2] - targetShape[2]) / 2)\n        self.endX \u003d self.startX + W\n        self.endY \u003d self.startY + H\n        # return the shape of the volume (we\u0027ll perform the actual\n        # crop during the forward pass\n        return [[batchSize, numChannels, H, W]]\n\n    def forward(self, inputs):\n        # use the derived (x, y)-coordinates to perform the crop\n        return [inputs[0][:, :, self.startY:self.endY,\n                self.startX:self.endX]]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Step 3:\nNow we construct a blob from out image that we pass through the holistic neural network.\nWhich after rescaling the resulting pixels back to int8 we have our edge image.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "(H, W) \u003d image.shape[:2]\nblob \u003d cv2.dnn.blobFromImage(image, scalefactor\u003d1.0, size\u003d(W, H),\n                                     mean\u003d(104.00698793, 116.66876762, 122.67891434),\n                                     swapRB\u003dFalse, crop\u003dFalse)\nnet.setInput(blob)\nhed \u003d net.forward()\nhed \u003d cv2.resize(hed[0, 0], (W, H))\nhed \u003d (255 * hed).astype(\"uint8\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "![](Edge_process_overview images/holistic.png \"Holistic results\")\nHolistic works really well at actually finding the edges of the images. It even works\nin cases with the islands that were shown in the second ISODATA image. On the other \nhand it does not really do accuracy really well. As you can see the resulting edges on the image\nare several pixels wide. Which prevents holistic from being the method of choice for coastline\nextraction. It does make Holistic the best tool to test any of the other methods to ensure that \nthey are not failing in there process.\n\n# Planet Imagery Conversions\nThis is not an edge detection process. It instead is about converting the TIFF files that \nrepresent the data from Planet labs to a format that is usable by all of the opencv \nmethods that are used in this project. I\u0027m including this because this is currently done\nusing terminal commands that are given to gdal_translate. I attempted to convert this process\nto python but was unable to do so. If you are able to figure this out I HIGHLY RECOMMEND THAT \nYOU CHANGE THE CURRENT CODE.\n\nAnyway here are the commands and what they are doing. Which I will not actually show in the\npython console since the only alteration is wrapping the command in a sys.system call.\n\nFirst command:\ngdal_translate tiff_file intermediate_tif -b 3 -b 2 -b 1 -co COMPRESS\u003dDEFLATE -co PHOTOMETRIC\u003dRGB\nThis command takes out the first three bands of the original tiff file and moves them to correct band\nstructure for an RBG image\n\ngdalinfo -mm intermediate_tif\nThe next command is used to obtain the pixel min and max for each of the bands. The min and max for the\nentire file are then used in the below command.\n\ngdal_translate intermediate_tif scaled_tif -scale 570 23800 0 65535 -exponent 0.5 -co COMPRESS\u003dDEFLATE -co PHOTOMETRIC\u003dRGB\nNow the tif file has its pixel values rescaled to values of a correct scale for showing color images.\nIf this command is not run the image appears very dark.\n\ngdal_translate -of JPEG -scale -co worldfile\u003dyes scaled_tif final_file_name\nFinally this last command translates the tif file into a JPEG file.\n\n\n# Help Installing opencv\nInstalling opencv can be a major pain. There are some binary packages that you can install\nbut one of the problems with those is that sometimes are unable to perform I/O or other\nimportant functions. So I\u0027m including some resources to help you install opencv\n\nThe easiest way that I found is to install __[Anaconda](https://www.anaconda.com/)__\nthen use the following command in the terminal\nconda install -c conda-forge opencv\n\nOtherwise the following are some good tutorials to install opencv \n__[pyimagesearch](https://www.pyimagesearch.com/2018/09/19/pip-install-opencv/)__\n__[pydeeplearning](https://pydeeplearning.com/opencv/install-opencv-with-c-on-ubuntu-18-04/)__\n\nTake the easy way is what I recommend since install opencv is highly machine \ndependent so it is very easy to run into problems.\n\n\n# Wrap up\nI hope that this was enough for you to be able to have an overview of all of the edge \ndetection methods that I have implemented. I know that the next stage of the project is\nto output the edge results of some of these processes to the band layers of the \noriginal tiff files. I recommend using ISODATA with Holistic as a testing backup.\nWhile possible including Canny Edge if you want to. Just find a way to set the \nthreshold values that works.\n\nThe resulting band layers should be enough to allow you to construct vectors that you\nwill need to began to actually track the coastlines over a time series, Good luck.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}